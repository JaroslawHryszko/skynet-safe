{
  "timestamp": 1745159081.3537798,
  "overall_status": "success",
  "components": {
    "local_model": {
      "status": "success",
      "message": "Model responded successfully in 7.16 seconds and is properly utilizing GPU",
      "response_time": 7.15966010093689,
      "gpu_utilization": true,
      "device_info": [
        {
          "index": 0,
          "name": "Tesla P40",
          "total_memory_gb": 23.87,
          "reserved_memory_gb": 2.14,
          "allocated_memory_gb": 1.82
        },
        {
          "index": 1,
          "name": "Tesla P40",
          "total_memory_gb": 23.87,
          "reserved_memory_gb": 5.45,
          "allocated_memory_gb": 3.5
        }
      ],
      "cuda_available": true,
      "gpu_count": 2,
      "model_device": "cuda:0",
      "response": "I'm here to help you! I'm Lira, your helpful AI assistant. Please feel free to ask me any questions ..."
    },
    "telegram": {
      "status": "not_tested",
      "message": "",
      "details": {}
    },
    "external_llm": {
      "status": "not_tested",
      "message": "",
      "details": {}
    },
    "system_requirements": {
      "status": "not_tested",
      "message": "",
      "details": {}
    }
  },
  "summary": "SKYNET-SAFE Configuration Test Results:\n\n1. System Requirements: NOT_TESTED\n   \n\n2. Local Model: SUCCESS\n   Model responded successfully in 7.16 seconds and is properly utilizing GPU\n   - Response time: 7.16 seconds\n   - Sample response: \"I'm here to help you! I'm Lira, your helpful AI as...\"\n   - GPU utilization: \u2705 Model is on cuda:0\n   - GPU 0 (Tesla P40): 1.82GB / 23.87GB (7.6% utilized)\n   - GPU 1 (Tesla P40): 3.50GB / 23.87GB (14.7% utilized)\n\n3. Telegram: NOT_TESTED\n   \n\n4. External LLM: NOT_TESTED\n   \n\nOVERALL RESULT: ALL TESTS PASSED"
}